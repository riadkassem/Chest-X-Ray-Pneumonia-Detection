import tensorflow as tf

from tensorflow.keras import layers, models

%matplotlib inline

import matplotlib.pyplot as plt

import numpy as np
IMG_SIZE = (150, 150) ## Resizing images

BATCH_SIZE = 32
import kagglehub



# Download latest version

path = kagglehub.dataset_download("paultimothymooney/chest-xray-pneumonia")



print("Path to dataset files:", path)
dataset_dir = "/kaggle/input/chest-xray-pneumonia/chest_xray"

train_ds = tf.keras.utils.image_dataset_from_directory(

    f"{dataset_dir}/train",

    image_size=IMG_SIZE,

    batch_size=BATCH_SIZE,

    label_mode='binary'

)



val_ds = tf.keras.utils.image_dataset_from_directory(

    f"{dataset_dir}/val",

    image_size=IMG_SIZE,

    batch_size=BATCH_SIZE,

    label_mode='binary'

)



test_ds = tf.keras.utils.image_dataset_from_directory(

    f"{dataset_dir}/test",

    image_size=IMG_SIZE,

    batch_size=BATCH_SIZE,

    label_mode='binary'

)

normalization_layer = layers.Rescaling(1./255)



AUTOTUNE = tf.data.AUTOTUNE



train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)).prefetch(AUTOTUNE)

val_ds   = val_ds.map(lambda x, y: (normalization_layer(x), y)).prefetch(AUTOTUNE)

test_ds  = test_ds.map(lambda x, y: (normalization_layer(x), y)).prefetch(AUTOTUNE)
import os

from collections import Counter



def count_classes(folder):

    normal = len(os.listdir(f"{folder}/NORMAL"))

    pneumonia = len(os.listdir(f"{folder}/PNEUMONIA"))

    return {'NORMAL': normal, 'PNEUMONIA': pneumonia}



print("Train:", count_classes(f"{dataset_dir}/train"))

print("Test:", count_classes(f"{dataset_dir}/test"))
images, labels = next(iter(train_ds))

plt.figure(figsize=(12, 12))



for i in range(9):

    ax = plt.subplot(3, 3, i + 1)

    # images[i] is already [0,1] floats, no conversion needed

    plt.imshow(images[i].numpy())

    label = "Normal" if labels[i] == 0 else "Pneumonia"

    plt.title(label)

    plt.axis("off")



plt.show()

from tensorflow.keras import mixed_precision



# Disable mixed precision

mixed_precision.set_global_policy('float32')





# Data augmentation

data_augmentation = tf.keras.Sequential([

    layers.RandomFlip('horizontal'),

    layers.RandomRotation(0.1),

    layers.RandomZoom(0.1),

])



model = models.Sequential([

    layers.Input(shape=(150, 150, 3)),

    data_augmentation,



    layers.Conv2D(32, (3, 3), activation='relu'),

    layers.MaxPooling2D(2, 2),



    layers.Conv2D(64, (3, 3), activation='relu'),

    layers.MaxPooling2D(2, 2),



    layers.Conv2D(128, (3, 3), activation='relu'),

    layers.MaxPooling2D(2, 2),



    layers.Flatten(),               # flatten before dense

    layers.Dense(64, activation='relu'),

    layers.Dense(1, activation='sigmoid')  # binary classification

])



model.summary()
model.compile(

    optimizer='adam',

    loss='binary_crossentropy',

    metrics=['accuracy']

)
history = model.fit(

    train_ds,

    validation_data=val_ds,

    epochs=10  # or more if you want

)

import numpy as np

from sklearn.metrics import classification_report, confusion_matrix

import seaborn as sns

import matplotlib.pyplot as plt



# Get all true labels

y_true = np.concatenate([y for x, y in test_ds], axis=0)



# Get model predictions

preds = model.predict(test_ds)

y_pred = (preds > 0.5).astype(int).flatten()  # for binary classification



# Classification report

print(classification_report(y_true, y_pred, target_names=['NORMAL', 'PNEUMONIA']))



# Confusion matrix

cm = confusion_matrix(y_true, y_pred)

sns.heatmap(cm, annot=True, fmt='d', xticklabels=['NORMAL', 'PNEUMONIA'], yticklabels=['NORMAL', 'PNEUMONIA'])

plt.xlabel('Predicted')

plt.ylabel('Actual')

plt.show()

plt.plot(history.history['accuracy'], label='train acc')

plt.plot(history.history['val_accuracy'], label='val acc')

plt.plot(history.history['loss'], label='train loss')

plt.plot(history.history['val_loss'], label='val loss')

plt.legend()

plt.show()
